{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make sure you have created a dedicated conda environment with the correct python version\n",
    "before proceeding with the next cells of this notebook.\n",
    "\n",
    "When done, select the correct Jupyter Notebook kernel and proceed to the next cell.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure your soundfiles are placed into the /data/raw/train and data/raw/test forlders.\n",
    "train_soundfiles = 'my_train_audiofiles_folder'\n",
    "test_soundfiles = 'my_test_audiofiles_folder'\n",
    "\n",
    "# Define a validation set\n",
    "#val_soundfiles = 'my_val_audiofiles_folder'\n",
    "# If not precise which dataset from the val set will be created\n",
    "split = \"train\"\n",
    "\n",
    "# Name your run\n",
    "run_name = 'my_run'\n",
    "\n",
    "# Enter the desire SR\n",
    "sr = 24000\n",
    "\n",
    "# Enter the duration of classification window (segment length) either in samples (samps) or in millisecond (ms)\n",
    "# This value depends on the duration of your IPTs, e.g.: if you wish to detect legato, a larger segment length is recommended\n",
    "segment_length = '1000 ms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command will launch the preprocessing of your files\n",
    "!python preprocess.py --name {run_name} --sampling_rate {sr} --train_dir {train_soundfiles} --test_dir {test_soundfiles} -seglen \"{segment_length}\" --val_split {split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When processing done, set the parameters for the training\n",
    "device = 'cpu' # or 'cuda' if you have a Nvidia GPU device on your machine\n",
    "model = 'flute' # or 'eguitar', both can work for other instruments, these names are related to models used for our papers\n",
    "epochs = 100 # number of training loops\n",
    "online_augment = 1 # if you wish to apply transformation on data during training, helps for generalization; recommended\n",
    "early_stopping = 10 # if you wish to stop the training process when the classification performance is not increasing anymore; recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command will launch the training of your classification model\n",
    "!python train.py --name {run_name} --sampling_rate {sr} -seglen \"{segment_length}\" --device {device} --model {model} --epochs {epochs} --online_augment {online_augment} --early_stopping {early_stopping}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "After the training stops, your classification model is available into the '/runs/your_run_name_date_time/' folder.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
